---
title: "Exploring RNA-seq data from Gierlinski, Schurch and Barton"
author: "Mustafa Abu El-Qumsan & Jacques van Helden"
date: '`r Sys.Date()`'
output:
  html_document:
    fig_caption: yes
    highlight: zenburn
    theme: cerulean
    toc: yes
    toc_depth: 3
  pdf_document:
    fig_caption: yes
    highlight: zenburn
    toc: yes
    toc_depth: 3
  word_document: default
bibliography: bibliography_rna-seq.bib
---

* * * * * * 

## Parameters for the execution of this tutorial

```{r knitr setup, include=FALSE,  eval=TRUE, echo=FALSE, warning=FALSE}
library(knitr)
knitr::opts_chunk$set(echo=FALSE, eval=TRUE, cache=FALSE, message=FALSE, warning=FALSE, comment = "")
```



```{r execution parameters}

## The variable dir.base should be adapted to indicate the path of the
## rna-seq_replicate_analysis clone on your computer. 
## All other directories and files are defined relative to this base directory. 
dir.base <- "~/rna-seq_replicate_analysis"
setwd(dir.base)



## Load required libraries
source(file.path(dir.base, 'R-scripts/install_required_libraries.R'))

## Define and check output directories
dir.results <- file.path(dir.base, "results")
dir.create(dir.results, showWarnings = FALSE, recursive = TRUE)
dir.figures <- file.path(dir.base, "figures")
dir.create(dir.figures, showWarnings = FALSE, recursive = TRUE)

```



## Introduction


The goal of this tutorial is to get familiar with RNA-seq data: 

- load a table of read counts per gene;
- do some exploratory statistics about these counts per gene (distributions, histograms, ...)




### Data source

[@Gierlinski:2015jt]

1. Gierliński,M., Cole,C., Schofield,P., Schurch,N.J., Sherstnev,A., Singh,V., Wrobel,N., Gharbi,K., Simpson,G., Owen-Hughes,T., et al. (2015) Statistical models for RNA-seq data derived from a two-condition 48-replicate experiment. Bioinformatics, 10.1093/bioinformatics/btv425.


[@Schurch:2015vk]

2. Schurch,N.J., Schofield,P., Gierliński,M., Cole,C., Sherstnev,A., Singh,V., Wrobel,N., Gharbi,K., Simpson,G.G., Owen-Hughes,T., et al. (2015) Evaluation of tools for differential gene expression analysis by RNA-seq on a 48 biological replicate experiment. arXiv.


### Methods


Fang and coworkers [-@Fang:2012fg] compares different statistical models and tests (Poisson, Fisher, negative binomial, ...) for the detection of differentially expressed genes. 

#### Full original datasets (beware, there are 672 fastq files !)

Data shared at ENA: <https://figshare.com/articles/Metadata_for_a_highly_replicated_two_condition_yeast_RNAseq_experiment_/1416210>

Fastq files: <http://www.ebi.ac.uk/ena/data/view/ERP004763>

#### Read count tables

- Wild-type yeast strains (WT): <https://dx.doi.org/10.6084/m9.figshare.1425503>
- Snf2 mutant: <https://dx.doi.org/10.6084/m9.figshare.1425502>


## Data loading

We will now load the two read count tables (WT and Snf2 mutants respectively).

```{r data loading}

## Load two tables containing the counts per gene for the wild-type (WT) and for the mutant (Snf2) strains, respectively. 
dir.counts <- file.path(dir.base, "data/counts_per_gene")
counts.wt <- read.delim(file=file.path(dir.counts, "WT_raw.tsv"), row.names = 1)
names(counts.wt) <- paste(sep=".", "WT", 1:ncol(counts.wt))

counts.snf2 <- read.delim(file=file.path(dir.counts, "Snf2_raw.tsv"), row.names = 1)
names(counts.snf2) <- paste(sep=".", "SNF2", 1:ncol(counts.snf2))

sample.groups <-c("WT", "Snf2")

```

## Data exploration

We will first check the dimension of the two tables.

```{r}

## count the number of genes (rows) in the two data tables.
dim(counts.wt)
dim(counts.snf2)

## Check if the row names (gene names) are the same in the two data tables
genes.wt <- row.names(counts.wt)
genes.snf2 <- row.names(counts.snf2)

## Count the number of different genes (should give zero)
if (sum(genes.wt != genes.snf2) > 0) {
  stop("The WT and Snf2 tables do not contain the same number of rows")
}
## OK, it gives 0. 

## Merge the two count tables in a single table
counts <- cbind(counts.wt, counts.snf2)

## Prepare a sample description table
## THIS DOES NOT WORK BECAUSE THE COUNT TABLE CONTAINS 96 columns, i.e. one column per sample, WHEREAS THE sample mapping table contains 7 technical replicates per sample. 
## sample.descriptions <- read.delim(file.path(dir.base, "data/ERP004763_sample_mapping.tsv"), row.names=1)

## Sample description table
sample.description <- data.frame(
  row.names = names(counts),
  genotype = c(rep("WT", times=ncol(counts.wt)), 
               rep("SNF2", times=ncol(counts.snf2))),
  replicate = c(1:48, 1:48)
  )


## Associate one specific color to each genotype
color.code <- c("WT"="#BBBBDD", "SNF2"="#FFBBBB")
sample.description$color <- color.code[sample.description$genotype]

```


The tables *counts.wt* and *counts.snf2* contain the read counts per gene for the Wild-Type  and the Snf2 strains, respectively. Each table contains one row per gene and one column per sample. 


| Genotype |  Rows | Columns |
|----------|-------|---------|
| WT | `r nrow(counts.wt)` |  `r ncol(counts.wt)` |
| Snf2 | `r nrow(counts.snf2)` |  `r ncol(counts.snf2)` |
| All | `r nrow(counts)` | `r ncol(counts)` |
| | |


## Summary of counts per sample (column)

We could use the function *summary()* to compute descriptie statistics for each column of the count table. 

```{r summary of  the counts}
## summary(counts) ## This takes too much place for a report
```

We can immediately draw some observations from these summaries. 

- **min**: in each column, the mean is 0. This corresponds to genes that were undetected: apparently these genes are either not transcribed, or they are transcribed at a weak level so that they were not sequenced in the library. 

- **Mean**: in this experiment the mean counts per gene are of the order of 1000 counts per gene for each biological sample. 

- **max* The max count is immensely larger than the mean counts, and this is true for each column. This observation is very general with RNA-seq data: in all the cases I have studied so far, we detect a very few genes having a huge number of counts. 

- **median** is the count value that splits the sorted values in two. Half of the values of a column are smaller than or equal to the median. 


## Number of undetected genes per sample

We would like to count the number of undetected genes per sample, i.e. genes having zero counts. 

```{r undetected_genes}
## Count the number of undetected genes for each sample
undetected.genes.per.sample <- apply(counts == 0, 2, sum)

## Count the number of samples where each gene has not been detected
undetected.samples.per.gene <- apply(counts == 0, 1, sum)
hist(undetected.samples.per.gene, breaks=0:ncol(counts), col="grey", ylim=c(0,300),
     main="Samples with zero counts per gene",
     xlab="Number of samples with 0 counts",
     ylab="Number of genes (truncated axis)"
  )
```

```{r WT vs Snf2 undetected}

## Compare the number of samples where each gene was detected in the two groups
detected.samples.per.gene.wt <- apply(counts.wt >= 1, 1, sum)
detected.samples.per.gene.snf2 <- apply(counts.snf2 >= 1, 1, sum)
plot(detected.samples.per.gene.wt, detected.samples.per.gene.snf2,
     main="detected genes in WT versus Snf2 samples",
     xlab="WT samples with zero counts",
     ylab="SNf2 samples with zero counts",
     panel.first=grid(col="blue"))
abline(a=0, b=1, col="darkgreen")

## Highlight the Snf2 gene on the plot
points(detected.samples.per.gene.wt["yor290c"], 
       detected.samples.per.gene.snf2["yor290c"], col="red")
```


## Compute the log-transformed counts


RNA-seq count data are characterized by a very wide range of values, with small count numbers of the majority of the genes, and a small number of genes having hundreds fo thousands of counts. For many purposes (visualisation, summarization, ...), it is more relevant to work with log2-transformed counts. 


However, we first must treate a problem: since many genes have 0 counts, the logarithmic transformation would give -Infinite, which creates problems for both computation and display. To circumvent this, we arbitrarily convert the zero counts in a small epsilon value (smaller than 1, so we can distinguish the genes with 1 counts from genes with 0 counts). we will choose an epsilon of 0.01.  

```{r log_counts_computation}
epsilon <- 1/4

## Compute log2-transformed counts
## sum(counts == 0) ## Count the number of zero values
counts.epsilon <- counts
counts.epsilon[counts == 0] <- epsilon
counts.log2 <- log2(counts.epsilon)

```


## Box plots


The boxplots below summarizes the distribution of log2-transformed counts per genes for each sample. 

```{r boxplots of log2-transformed count, fig.height=12, fig.width=6, fig.cap="Box plot of the log2-transformed counts per sample. Zero values were converted to an epsilon=1/4 before log2-transformation, and this appear as -2 on the log2-transformed plots. "}

for (genotype in c("WT", "SNF2")) {
  boxplot(counts.log2[,sample.description$genotype == genotype], 
          horizontal = TRUE, las=2, col=color.code[genotype],
          main=genotype,
          xlab=paste(sep="", "log2(counts), with epsilon=", epsilon))
  
}

```



* * * * * * * * *

## Normalization of RNA-seq counts

The total number of counts (``libsum'') can show wide variations from sample to sample, resulting from various sources (biological sample, sequencing, mapping, ...). Before comparing the counts per gene between different samples, it is important to perform a between-sample normalization. 

Several methods have been proposed for this. 

### Counts per million (CPM)

Counts are converted to counts per million by a simple scaling rule. 

We dispose of a raw count table containing `r nrow(counts)` rows (one row per gene) and `r ncol(counts)` columns (one column per sample). 

Let us define $x_{i,j}$ as the count of reads for gene $i$ ($i^{th}$ row) in sample $j$ ($j^{th}$ column). 

We can compute the sum of counts for each sample (column), which is also called the ***libsum***.

$$N_j = \sum_{i=1}^{g}{x_{i,j}}$$

where $g$ is the total number of genes (rows in the table).

The basic way to compute counts per million reads is to divide each count by the libsum of the corresponding sample (column), and multiplying by 1 million for scaling purposes.

$$cpm_{i,j} = \frac{n_{i,j}}{N_j} \cdot 1,000,000$$

### Median-based standardization

A well-known problem with this simple approach is that the libsum can be strongly influenced by outliers, i.e. a handful of genes which are represented by hundreds of millions of reads. 

To circumvent this, one possibility is to use a more robust scaling factor for each sample, for example the median count, or the  $75^{th}$ percentile. 

$$x'_{i,j} = \frac{x_{i,j}}{\text{median}(x_{.j})} \cdot \text{median}(x_{i,j})$$





### When should we use / not use normalized counts?

Normalized log2-transformed counts are very  convenient for display purposes (e.g. to compare the read density between samples or between conditions). 

**However**, they cannot be used for all purposes. Indeed, the normalization procedure converts integer counts into fractional numbers, which do not comply with the probabilistic models underlying manysome of the statistical tests that are performed on these datasets. In particular, the most popular packages for differential  analysis with RNA-seq expect to take as input a table with raw counts. 

The log2 transformation completely modifies the nature of the data, and completely change the scale of the counts. Consequently, log2-transformed data should not be used either as input for the classical differential analysis packages. 

Log2-transformed standardized counts may also be interesting for some clustering or classification purposes, because they will strongly reduce the dynamic range of the data, and the *log2 transformation has a normalizing effect* (this is a general effect) that may contribute to increase the suitedness of the data for some analysis methods (e.g. PCA, clustering, discriminant analysis, ...). We will investigate this very soon. 


* * * * * * * * *

## Exercises

### Exercise 1. Summary statistics

Compute a table with summary statistics per samples (columns of the count table). In particular, include in this table the following statistics. All statistics should be computed on both the raw counts and log2-transformed counts. 

a. Sum of counts in the sample.
b. Median count per sample.
c. Some illustrative percentiles (0=min, 5, 10, 25, 50, 75, 90, 95, 100=max)
d. Inter-Quartile Range (IQR).
e. Classical statistical estimates (mean, variance, standard deviation).
f. Any other statistics that you moght find relevant.

The result table must contain one row per sample (column of the original count table), and one column  per statistics (points a to f above). 

Hereafter we only display the results for the 10 first samples (columns of the table), for the sake of readibility of the report. However we also calculate the same statistics for each one of the samples (the full table of statistics will be exported in a tab-separated value file).


```{r summary ststistics per sample NEW NEW}


## Prepare a data frame to store the statistics per sample


## Collact sample-wise statistics in a data frame
stats.per.sample <- data.frame(
  mean = apply(counts, 2, mean),
  sd = apply(counts, 2, sd),
  var = apply(counts, 2, var),
  min = apply(counts, 2, min),
  median = apply(counts, 2, median),
  max = apply(counts, 2, max),
  sum = apply(counts, 2, sum),
  IQR=apply(counts, 2, IQR)
)

selected.quantiles <- c(0,0.05,0.1,0.25,0.50,0.75,0.9,0.95,0.99, 1)
sample.quantiles <-  round(t(apply(counts, 2, quantile, selected.quantiles)), digits=1)

colnames(sample.quantiles) <- paste(sep="", "Q", sprintf("%.2f",selected.quantiles))
stats.per.sample <- cbind(stats.per.sample, sample.quantiles)

 #View(stats.per.sample)

## Export the full table with statistics per sample
write.table(x = stats.per.sample, sep="\t", quote = FALSE, col.names=NA,
            file = file.path(dir.results, "stats_per_sample.tab"))


## Print the 10 first rows of the table in markdown format so that it will be nicely displayed in the HTML report
knitr::kable(t(stats.per.sample[1:10,]))

```

### Exercise 2. Sample-wise standardization

In this exercise we apply a simplistic method to standardize samples. Note that specialized packages like edgeR and DESeq2 have much more elaborate (and relevant) normalization procedures. This simplistic normalization is only for didactic purposes. 

a. Standardize the count table by scaling all values accoding to the median per sample (do it for the counts and for the log2-transformed counts).
b. Compare the scaling factors that would be applied with libsum and median-based standardization, respectively (draw a plot comparing the scaling factors for each sample). 

```{r statistics per Sample}

## Compute the median per column
median.per.column <- apply(counts, 2, median)

## Compute the global median count for all the samples together
median.count.allsamplestogether <- median(unlist(counts))
dim(counts)

## Plot a histogram to show the widespread of the median count per sample
hist(median.per.column, breaks=100, col="cyan")
abline(v=median.count.allsamplestogether, col="darkgreen", lwd=3)

## Compute the median-normalized counts for each sample, by taking the ratio between sample-wise median count and global median count
counts.mednorm <- counts.epsilon
for (j in 1:ncol(counts.mednorm)) {
  counts.mednorm[,j] <-   counts.epsilon[,j] / median.per.column[j] * median.count.allsamplestogether
}

## Control: run the commented line before and check that all columns have the same median (they should, since we performed a median-based scaling).
##       print(apply(counts.mednorm, 2, median))

## Compute the log2-transformed counts after median-based standardization
counts.mednorm.log2 <- log2(counts.mednorm)

```


#### Boxplots of sample-wise standardized counts (log2-transformed)

```{r boxplots of log2-transformed median-based normalized count, fig.height=12, fig.width=8, fig.cap="Box plot of the  median-based normalized and log2-Introduction to differential gene expression analysis using RNA-seqtransformed counts. Zero values were converted to an epsilon=1/4 before log2-transformation, and this appear as -2 on the log2-transformed plots. "}

for (genotype in c("WT", "SNF2")) {
  boxplot(counts.mednorm.log2[,sample.description$genotype == genotype], 
          horizontal = TRUE, las=2, col=color.code[genotype],
          main=genotype,
          xlab=paste(sep="", "median-based normalized log2(counts), with epsilon=", epsilon))
}

```

### Exercise 3. Normalizing effect of the log2 transformation

Plot an histogram of the raw counts (all the table) versus log2-transformed median-based normalized counts.


```{r plot histograms of log2-transformed versus raw counts, fig.width=12, fig.height=5}
par(mfrow=c(1,2)) 
hist(unlist(counts), breaks=20000, xlim=c(0,5000), main="Raw counts (truncated X axis)", col="#DDBBFF")
hist(unlist(counts.mednorm.log2),  breaks=100, main="log2-transformed, median-normalized counts", col="#BBDDDD")
par(mfrow=c(1,1))
```


This distribution does not look like any conventional distribution, but this is not surprizing. Indeed, each gene can be considered as a separate object for which we measure the level of expression in two different samples, and which follows its own distribution. The histograms above can thus be understood as a mixture of ~7000 (number of genes) times 2 (nuber of genotypes) independent distributions, each of which is represented by 48 observations (replicates). 

### Exercise 4. Statistics per gene (rows of the count table)

Based on the standardized log2-transformed counts, compute a table with statistics per gene: for each gene, compute the mean, sd, var, min, median, max, IQR, and a few selected quantiles (0, 0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.95,  1), ...

<font color="red">
**Mustafa: please do the same as what we did above for the samples (columns of the count table), but apply it to genes (rows of the count table).
</font>

```{r stats_per_gene}
## Compute gene-wise statistics
stats.per.gene <- data.frame(
  mean= apply(counts, 1, mean),
  sd= apply(counts, 1, sd),
  var= apply(counts, 1, var),
  min= apply(counts, 1, min),
  median= apply(counts, 1, median),
  max= apply(counts, 1, max),
  IQR= apply(counts, 1, IQR)
  )

## Compute the log2-transformed counts after median-based standardization
counts.mednorm.log2 <- log2(counts.mednorm)

selected.quantiles <- c(0,0.05,0.1,0.25,0.50,0.75,0.9,0.95,0.99,1)

gene.quantiles <-  round(t(apply(counts, 1, quantile, selected.quantiles)), digits=1)
dim(gene.quantiles)
colnames(gene.quantiles) <- paste(sep="", "Q", sprintf("%.2f",selected.quantiles))
colnames(gene.quantiles)
stats.per.gene <- cbind(stats.per.gene, gene.quantiles)
colnames(stats.per.gene)
#  View(stats.per.gene)

## Export the full table with statistics per Gene
write.table(x = stats.per.gene, sep="\t", quote = FALSE, col.names=NA,
            file = file.path(dir.results, "stats_per_gene.tab"))


## Print the 10 first rows of the table in markdown format so that it will be nicely displayed in the HTML report
knitr::kable(t(stats.per.gene[1:10,]))
```



### Exercise 5. Comparison between WT and mutant genotypes

a. Compute the mean counts per gene for each genotype, using the median-based standardized log2-transformed counts. 
b. Draw a plot to compare the mean expression per gene between WT and SNF2 genotypes. 



```{r fig.width=7, fig.height=7, fig.cap="Comparison of mean read counts per gene between the two genotypes. Note that this drawing is very preliminary, since we did not yet normalize the libraries. It is just to get a rough idea. "}

## Compute mean counts per sample class for each gene
stats.per.gene$WT.mean <- apply(counts.wt, 1, mean)
stats.per.gene$Snf2.mean <- apply(counts.snf2, 1, mean)

## Compute, for each gene, the mean value for each of the two groups
## We define colors with the 6 hexadecimal numbers 
## (ex: http://coolmaxhot.com/graphics/hex-color-palette.htm)
## see also https://terpconnect.umd.edu/~toh/ColorLesson/ for explanation of color perception
plot(stats.per.gene$WT.mean, stats.per.gene$Snf2.mean,
     main="Mean read counts per gene",
     col="#006688",
     xlab="WT genotype",
     ylab="Snf2 genotype"
    )
grid(col="blue")
abline(col="brown", a=0, b=1) ## Draw a diagonal (slope=1, intercept=0)
abline(h=0, col="black") # Draw an horizontal line to mark X axis
abline(v=0, col="black") # Draw a vertical line to mark Y axis

```


### Log2 mean values

We can also  draw a plot with the mean of the log2-transformed counts. 
Note that the arithmetic mean of the logarithms is equivalent to the logarithm of the geometric mean. 

$$\frac{1}{n}\sum_{j=1}^{n}{log_2(x_{i,j})} = log_2(\sqrt[n]{\prod_{j=1}^{n}{x_{i,j}}})$$

```{r fig.width=7, fig.height=7, fig.cap="Comparison of mean read log2(counts) per gene between the two genotypes. Note that this drawing is very preliminary, since we did not yet normalize the libraries. It is just to get a rough idea. "}

## Compute mean counts per sample class for each gene
stats.per.gene$WT.log2.mean <- apply(counts.log2[, sample.description$genotype=="WT"], 1, mean)
stats.per.gene$Snf2.log2.mean <- apply(counts.log2[, sample.description$genotype=="SNF2"], 1, mean)

plot(stats.per.gene$WT.log2.mean, stats.per.gene$Snf2.log2.mean,
     main="Mean log2-transformed read counts per gene",
     col="#008844",
     xlab="WT genotype; log2(counts)",
     ylab="Snf2 genotype; log2(counts)"
    )
abline(a=0,b=1, col="#FF0066", lwd=2)
abline(v=0, col="black")
abline(h=0, col="black")
grid(col="blue")

```


## Next steps


1. Do the exercises above (exploration of the data)
2. Learn to use the *DESeq2* and *edgeR* packages by using the Vignettes. 
3. Run DESeq2 and edgeR on the yeast dataset, in order to detect differentially expressed genes between WT and Snf2. 
4. After that, you will analyse the robustness of the lists of differentially expressed genes by running resampling approaches (bootstrap, jacknife, subsampling). 

Regularly we discuss about the results and interpret. 

```{r by using EdgeR, we filtering out low count reads since it would be impossible to detect diffrential expression}
dim(counts)
cds<-DGEList(counts)
names(cds)
head(cds$counts)
cds$samples 
sum(cds$all.zeros)
dim(cds)

cds <- cds[rowSums(1e+06 * cds$counts/expandAsMatrix(cds$samples$lib.size, dim(cds)) > 1) >= 3, ]
dim(cds)
cds <- calcNormFactors(cds)
cds$samples
cds$counts
cds$samples$lib.size * cds$samples$norm.factors
```    

```{r we need to plot measures the similarity of the samples by using Multi-Dimensional Scalling Plot}
plotMDS( cds , main = "MDS Plot for Count Data", labels = colnames( cds$counts ) )
```

```{r now we Estimating Dispersions }
## to calculate a commen dispersion, each gene gets assigned the same dispersion estimate 
cds <- estimateCommonDisp( cds )
names(cds)
cds$common.dispersion 

## the implied standerd deviation are the squere-roots of the Variances
SD <- sd(cds$counts)
sqrt(SD)

cds <- estimateTagwiseDisp(cds, prior.df =   10)
summary(cds$tagwise.dispersion)
## More shrinkage / Sqeezing toward the common 
cds <- estimateTagwiseDisp(cds , prior.df = 25)
summary(cds$tagwise.dispersion)
```

```{r Plotting the Mean-Variance relationship }
meanVarPlot <- plotMeanVar(cds, show.raw.vars = TRUE ,
                           show.tagwise.vars = TRUE   ,
                           show.binned.common.disp.vars = TRUE ,
                           show.ave.raw.vars = FALSE ,
                           dispersion.method = "qcml" , NBline = TRUE,
                           nbins = 100 ,
                           pch = 16 ,
                           xlab = "Mean Expression (Log10 Scale)" ,
                           ylab = "Variance (Log10 Scale)",
                           main = "Mean- Variance Plot")

```

```{r Visualizing Resulats}
par(mfrow=c(3 ,1))
#hist()
```



## References
